# 说明及配置 {#concept_rc2_t1h_wdb .concept}

## 概述 {#section_cf5_t1h_wdb .section}

OssImport工具可以将本地、其它云存储的数据迁移到OSS，它有以下特点：

-   支持的丰富的数据源，有本地、七牛、百度BOS、AWS S3、Azure Blob、又拍云、腾讯云COS、金山KS3、HTTP、OSS等，并可根据需要扩展；
-   支持断点续传；
-   支持流量控制；
-   支持迁移指定时间后的文件、特定前缀的文件；
-   支持并行数据下载、上传；
-   支持单机模式和分布式模式，单机模式部署简单使用方便，分布式模式适合大规模数据迁移。

## 运行环境 {#section_cwg_v1h_wdb .section}

-   Java 1.7及以上

## 部署方式 {#section_ttn_x1h_wdb .section}

OssImport有单机模式和分布式模式两种部署方式。

-   对于小于 30TB 的小规模数据迁移，单机模式即可完成。[下载地址](http://gosspublic.alicdn.com/ossimport/standalone/ossimport-2.3.1.zip?spm=a2c4g.11186623.2.4.tg6Ory&file=ossimport-2.3.1.zip)
-   对于大规模的数据迁移，请使用分布式模式。[下载地址](http://gosspublic.alicdn.com/ossimport/distributed/ossimport-2.3.1.tar.gz?spm=a2c4g.11186623.2.4.maVna1&file=ossimport-2.3.1.tar.gz)

单机

Master、Worker、Tracker、Console运行在一个机器上，系统中有且只有一个Worker。我们对单机模式的部署和执行进行了封装优化，单机部署和执行都很简单。单机模式下Master、Worker、TaskTracker、Console四个模块统一打包成`ossimport2.jar`。

单机模式下文件结构如下：

```
ossimport
├── bin
│ └── ossimport2.jar  # 包括Master、Worker、Tracker、Console四个模块的总jar
├── conf
│ ├── local_job.cfg   # 单机Job配置文件
│ └── sys.properties  # 系统运行参数配置文件
├── console.bat         # Windows命令行，可以分布执行调入任务
├── console.sh          # Linux命令行，可以分布执行调入任务
├── import.bat          # Windows一键导入，执行配置文件为conf/local_job.cfg配置的数据迁移任务，包括启动、迁移、校验、重试
├── import.sh           # Linux一键导入，执行配置文件为conf/local_job.cfg配置的数据迁移任务，包括启动、迁移、校验、重试
├── logs                # 日志目录
└── README.md           # 说明文档，强烈建议使用前仔细阅读
```

提示：

-   import.bat/import.sh为一键导入脚本，修改完`local_job.cfg`后可以直接运行；
-   console.bat/console.sh为命令行工具，可以用于分布执行命令；
-   脚本或命令时请在`ossimport`目录下执行，即 `*.bat/*.sh` 的同级目录。

分布式

OssImport是基于master-worker的分布式架构，如下图：

```
Master --------- Job --------- Console
    |
    |
   TaskTracker
    |_____________________
    |Task     | Task      | Task
    |         |           |
Worker      Worker      Worker
```

其中：

-   Job：用户通过提交的数据迁移任务，对用户来说一个任务对应一个配置文件`job.cfg`。
-   Task：Job按照数据大小和文件个数 可以分成多个Task ，每个Task 迁移部分文件。Job切分成Task的最小单位是文件，同一个文件不会切分到多个Task中。

OssImport各模块说明，如下表：

|角色|说明|
|:-|:-|
|Master|负责将Job切分成Task，按照数据大小和文件个数分解成Task，数据大小/文件个数可以在sys.properties中配置。Job切分成Task的详细过程是：1.  Master从本地/其它云存储中遍历出完整的待迁移的文件列表。
2.  按照数据大小和文件个数把完整的文件列表切分成Task，每个Task负责部分文件的迁移或校验。

 |
|Worker| -   负责Task的文件迁移和数据校验，从数据源上拉取指定文件，并上传到OSS的指定目录。迁移的数据源和OSS的配置在job.cfg或local\_job.cfg中指定
-   Worker数据迁移支持限流、指定Task并发数，在sys.properties中配置。

 |
|TaskTracker|简称Tracker，负责Task的分发、Task状态跟踪。|
|Console|负责与用户交互，接受命令显示结果。支持系统管理命令deploy/start/stop，Job管理命令 submit/retry/clean。|

分布式模式下可以启动多个Worker执行迁移数据，Task平均分配到Worker上执行，一个Worker执行多个Task。每一个机器上只能启动一个Worker。`workers`配置的第一个Worker 上会同时启动Master 、 TaskTracker、Console 也要在该机器上运行。

分布式模式下文件结构如下：

```
ossimport
├── bin
│ ├── console.jar     # Console模块jar包
│ ├── master.jar      # Master模块jar包
│ ├── tracker.jar     # Tracker模块jar包
│ └── worker.jar      # Worker模块jar包
├── conf
│ ├── job.cfg         # Job配置文件模板
│ ├── sys.properties  # 系统运行参数配置文件
│ └── workers         # Worker列表
├── console.sh          # 命令行工具，目前支持只Linux
├── logs                # 日志目录
└── README.md           # 说明文档，强烈建议使用前仔细阅读
```

提示：

-   分布式命令行工具 console.sh 目前只支持Linux，Windows暂不支持。

## 配置文件 {#section_c2z_ldh_wdb .section}

单机模式下有两个配置文件`sys.properties`、`local_job.cfg`，分布式模式下有三个配置文件`sys.properties`、`local_job.cfg`、`workers`。其中`local_job.cfg`和`job.cfg`是完全一样的，只是名称不一样，`workers`是分布式环境先独有的。

-   sys.properties

    系统运行参数。

    |字段|含义|说明|
    |:-|:-|:-|
    |workingDir|工作目录|     -   工具包解压后的目录。
    -   单机模式下请不要修改此选择。
    -   分布式模式下每个机器的工作目录必须相同。
 |
    |workerUser|Worker机器的ssh用户名|     -   如果配置了privateKeyFile ，则优先使用privateKeyFile。
    -   如果没有配置privateKeyFile，则使用workerUser/workerPassword。
    -   单机模式不需要修改此项。
 |
    |workerPassword|Worker机器的ssh用户密码|单机模式不需要修改此项。|
    |privateKeyFile|private key文件路径|     -   如果已经打通了ssh通道，则可以指定public key文件路径，否则为空。
    -   如果配置了privateKeyFile，则优先使用privateKeyFile。
    -   如果没有配置privateKeyFile，则使用workerUser/workerPassword。
    -   单机模式不需要修改此项。
 |
    |sshPort|ssh端口|默认22，一般情况无需更改 单机模式不需要修改此项。|
    |workerTaskThreadNum|Worker执行Task的最大线程数|     -   该参数与机器的内存/网络有关，建议值60 。
    -   物理机可以适当加大，比如150 ，如果网络已经打满，请不要再加大。
    -   如果网络较差，请适当降低，比如30，防止请求竞争网络造成大量请求超时。
 |
    |workerMaxThroughput\(KB/s\)|worker数据迁移的流量上限|该值能起到限流作用，默认0表示不限流。|
    |dispatcherThreadNum|Tracker的Task分发与状态确认的线程数|默认值一般够用，没有特殊需要请不要修改默认值。|
    |workerAbortWhenUncatchedException|表示遇到未知错误时是跳过还是Abort|默认跳过。|
    |workerRecordMd5|在OSS中是否使用元数据x-oss-meta-md5记录迁移文件MD5值，默认不记录。|主要用于用户使用MD5校验文件数据。|

-   job.cfg

    数据迁移任务配置，local\_job.cfg和job.cfg的配置项是完全一样的，只是名称不一样。

    |字段|含义|说明|
    |:-|:-|:-|
    |jobName|任务名字，字符串。|     -   任务的唯一标识，命名规则 \[a-zA-Z0-9\_-\]\{4,128\}， 支持提交多个名字不同的任务。
    -   如果重复提交同名任务会提示任务已存在，清理（clean）同名任务前， 无法提交同名任务。
 |
    |jobType|任务类型，字符串|两类import或audit，默认 import。    -   import，执行数据迁移操作并校验迁移数据的一致性。
    -   audit，仅进行数据一致性校验。
|
    |isIncremental|是否打开增量迁移模式，布尔类型。|     -   默认值false。
    -   如果设为true，会每间隔incrementalModeInterval\(单位秒\)重新扫描一次增量数据，并将增量数据迁移到OSS。
 |
    |incrementalModeInterval|增量模式下的同步间隔，整形，单位秒。|isIncremental=true时有效。可配置的最小间隔为900秒，不建议配置成小于 3600秒 的值，会浪费大量请求，造成额外的系统开销。|
    |importSince|迁移大于该时间的数据，整形，单位秒。|     -   该时间为 Unix时间戳，即自1970年1月1日UTC零点以来的秒数，通过命令date +%s获取。
    -   默认为0，表示迁移全部数据。
 |
    |srcType|同步源类型，字符串， 请注意大小写。|目前支持local、oss、qiniu、bos、ks3、s3、youpai、http、cos、azure等十种类型。    -   local，从本地文件迁移数据到OSS，该选项只需要填写srcPrefix， 不需要填写srcAccessKey，srcSecretKey，srcDomain，srcBucket。
    -   oss，从一个 bucket 迁移到另一个 bucket。
    -   qiniu，从七牛云存储迁移到OSS。
    -   bos，从百度的云存储迁移到OSS。
    -   ks3，从金山云存储迁移到OSS。
    -   s3，从 AWS S3 迁移到OSS。
    -   youpai，从又拍云迁移到到OSS。
    -   http，通过提供的HTTP链接列表迁移数据到OSS。
    -   cos，从腾讯云存储COS迁移到OSS。
    -   azure，从Azuer Blob迁移到OSS。
|
    |srcAccessKey|源AccessKey，字符串。|如果srcType设置为oss、qiniu、baidu、ks3、s3，填写数据源的AccessKey。    -   local、http，该项不需要填写。
    -   youpai、azure则填写用户名AccountName。
|
    |srcSecretKey|源SecretKey，字符串。|如果 srcType 设置为oss、qiniu、baidu、ks3、s3，填写数据源的 SecretKey。    -   local、http，该项不需要填写。
    -   youpai，填写操作员密码。
    -   azure，填写AccountKey。
|
    |srcDomain|源Endpoint|如果 srcType 设置为local、http，该配置项不需要填。    -   oss，从控制台获取的域名，非带bucket前缀的二级域名，列表请参看域名列表。
    -   qiniu，从七牛控制台获取的对应bucket的域名。
    -   bos，百度BOS域名，如`http://bj.bcebos.com` 或 `http://gz.bcebos.com`。
    -   ks3，金山ks3域名，如`http://kss.ksyun.com` 或 `http://ks3-cn-beijing.ksyun.com` 或 `http://ks3-us-west-1.ksyun.coms`。
    -   S3， AWS S3各 region 的域名请参考S3 Endpoint。
    -   youpai，又拍云域名，如自动判断最优线路`http://v0.api.upyun.com` 或电信线路`http://v1.api.upyun.com` 或联通网通线路`http://v2.api.upyun.com`或移动铁通线路`http://v3.api.upyun.com`。
    -   cos，腾讯云填写bucket所在的区域，比如华南园区:gz、华北园区:tj、华东园区:sh。
    -   azure，Azure Blob连接字符串中的 EndpointSuffix ，如core.chinacloudapi.cn。
|
    |srcBucket|源bucket名字或container名称。|如果 srcType 设置为local、http，不需要填写。azure，Azure Blob填写container名称，其它填写bucket名称。|
    |srcPrefix|源前缀，字符串，默认为空。|如果srcType=local，填写本地目录，需要完整路径，以/进行分割并且以/结尾，如 c:/example/或 /data/example/。srcType 为oss、qiniu、bos、ks3、youpai、s3，则为待同步object的前缀，不包括bucket名称，如data/to/oss/， 同步所有文件srcPrefix设置为空 。|
    |destAccessKey|目的AccessKey，字符串。|OSS的AccessKeyID，请到[阿里云控制台](https://oss.console.aliyun.com/index#/)查看

。|
    |destSecretKey|目的SecretKey，字符串。|OSS的AccessKeySecret，请到[阿里云控制台](https://oss.console.aliyun.com/index#/)查看

。|
    |destDomain|目的endpoint，字符串。|从[阿里云控制台](https://oss.console.aliyun.com/index#/)获取，非带bucket前缀的二级域名，列表请参看域名列表。

。|
    |destBucket|目的bucket，字符串。|OSS的bucket名称，不需要以/结尾。|
    |destPrefix|目标前缀，字符串，默认为空。|     -   目标前缀，默认为空，直接放在目标bucket下。
    -   如果要将数据同步到oss的某个目录下，请以/结尾，如data/in/oss/。
    -   注意oss不支持以/作为文件的开头，所以destPrefix请不要配置以/做为开头。
    -   一个本地文件路径为srcPrefix+relativePath的文件，迁移到oss的路径为destDomain/destBucket/destPrefix +relativePath。
    -   一个云端文件路径为srcDomain/srcBucket/srcPrefix+relativePath的文件，迁移到oss的路径为destDomain/destBucket/destPrefix+relativePath。
 |
    |taskObjectCountLimit|每个Task最大的文件数，整型，默认10000。|该配置项会影响到任务执行的并行度，一般配置为总文件数/Worker总数/迁移线程数\(workerTaskThreadNum\) ，最大值不要超过50000，如果不知道总文件数，请使用默认值。|
    |taskObjectSizeLimit|每个Task最大数据量，整型，单位bytes，默认1GB。|该配置项会影响到任务执行的并行度，一般配置为总数据量/Worker总数/迁移线程数\(workerTaskThreadNum\)，如果不知道总数据量，请使用默认值。|
    |isSkipExistFile|数据迁移时是否跳过已经存在的文件，布尔类型。|当设置为true时，根据文件的size和LastModifiedTime判断是否跳过；为false时，总是覆盖OSS上已有文件。默认为值为false。jobType为audit时此项不生效。|
    |scanThreadCount|并行扫描文件的线程数，整型，默认1。|该配置项与扫描文件的效率有关，没有特殊需求请不要修改。|
    |maxMultiThreadScanDepth|最大允许并行扫描目录的深度，整型，默认1。|     -   默认值1表示在顶级目录间并行扫描。
    -   没有特殊需求不要修改，随意配置过大值会导致任务无法正常运行 。
 |
    |appId|腾讯云COS的appId ，整型。|srcType=cos时有效。|
    |httpListFilePath|HTTP列表文件的绝对路径，字符串。|     -   srcType=http时有效，源为HTTP链接地址时，需要提供内容为HTTP链接地址文件的绝对路径，如c:/example/http.list。
    -   该文件中的HTTP链接需要划分成两列，以空格分开，分别代表前缀和上传到OSS后的相对路径。例如c:/example/http.list文件内容如：`http://mingdi-hz.oss-cn-hangzhou.aliyuncs.com/aa/ bb.jpg` `http://mingdi-hz.oss-cn-hangzhou.aliyuncs.com/cc/dd.jpg`两行，迁移到OSS的文件名分别是 destPrefix + bb.jpg和 destPrefix + cc/dd.jpg。
 |

-   workers

    workers是分布式模式先独有的，每个IP一行。如：

    ```
    192.168.1.6
    192.168.1.7
    192.168.1.8
    ```

    提示：

    -   上述配置情况下，第一行的`192.168.1.6`一定是 master ；即`192.168.1.6` 上会启动Master 、 Worker 、 TaskTracker 、Console也需要在该机上执行。
    -   多个Worker机器的用户名、登录方式、工作目录请确保相同。

## 配置文件示例 {#section_yjs_3gh_wdb .section}

下表中是分布式部署下的数据迁移任务配置文件，单机的配置文件名是`local_job.cfg`，配置项与分布式部署时没有区别。

|迁移类型|配置文件|说明|
|:---|:---|:-|
|从本地迁移到OSS|[job.cfg](https://github.com/aliyun/ossimport/blob/master/conf/local/job.cfg)|srcPrefix 是以 `/` 结尾的绝对路径，如 `D:/work/oss/data/`, `/home/user/work/oss/data/`|
|从七牛云存储迁移到OSS|[job.cfg](https://github.com/aliyun/ossimport/blob/master/conf/qiniu/job.cfg)|srcPrefix 和 destPrefix 可以配置为空；如果不为空，请以 `/` 结尾，如 `destPrefix=docs/`|
|从百度bos迁移到OSS|[job.cfg](https://github.com/aliyun/ossimport/blob/master/conf/bos/job.cfg)|srcPrefix 和 destPrefix 可以配置为空；如果不为空，请以 `/` 结尾，如 `destPrefix=docs/`|
|从AWS S3迁移到OSS|[job.cfg](https://github.com/aliyun/ossimport/blob/master/conf/s3/job.cfg)|S3的[域名列表](http://docs.aws.amazon.com/general/latest/gr/rande.html#s3_region)|
|从又拍云存储迁移到OSS|[job.cfg](https://github.com/aliyun/ossimport/tree/master/conf/youpai)|srcAccessKey/srcSecretKey填操作员账号及密码|
|从腾讯cos迁移到OSS|[job.cfg](https://github.com/aliyun/ossimport/blob/master/conf/cos/job.cfg)|srcDomain请按照V4版本填写，如`srcDomain=sh` ; srcPrefix可以为空，当不为空时候，请以 `/` 开头和结尾，如`srcPrefix=/docs/`|
|从Azure blob迁移到OSS|[job.cfg](https://github.com/aliyun/ossimport/tree/master/conf/blob)|srcAccessKey/srcSecretKey填存储存储账号及密钥；srcDomain填连接字符串中的 EndpointSuffix，如`core.chinacloudapi.cn`|
|从OSS迁移到OSS|[job.cfg](https://github.com/aliyun/ossimport/blob/master/conf/oss/job.cfg)|适用于不同区域之间、不同存储类型之间、不同前缀之间的数据迁移；推荐在ECS上部署，并使用带internal的域名，可以节省流量费用|
|使用高速通道迁移数据到OSS|[job.cfg](https://github.com/aliyun/ossimport/blob/master/conf/et/job.cfg)|适用于所有数据源，如果您有高速迁移需求，请提交工单或联系OSS支持人员|

